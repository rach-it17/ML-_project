{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e9ce4429",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Given Data     R&D Spend  Administration  Marketing Spend     Profit\n",
      "0   165349.20       136897.80        471784.10  192261.83\n",
      "1   162597.70       151377.59        443898.53  191792.06\n",
      "2   153441.51       101145.55        407934.54  191050.39\n",
      "3   144372.41       118671.85        383199.62  182901.99\n",
      "4   142107.34        91391.77        366168.42  166187.94\n",
      "5   131876.90        99814.71        362861.36  156991.12\n",
      "6   134615.46       147198.87        127716.82  156122.51\n",
      "7   130298.13       145530.06        323876.68  155752.60\n",
      "8   120542.52       148718.95        311613.29  152211.77\n",
      "9   123334.88       108679.17        304981.62  149759.96\n",
      "10  101913.08       110594.11        229160.95  146121.95\n",
      "11  100671.96        91790.61        249744.55  144259.40\n",
      "12   93863.75       127320.38        249839.44  141585.52\n",
      "13   91992.39       135495.07        252664.93  134307.35\n",
      "14  119943.24       156547.42        256512.92  132602.65\n",
      "15  114523.61       122616.84        261776.23  129917.04\n",
      "16   78013.11       121597.55        264346.06  126992.93\n",
      "17   94657.16       145077.58        282574.31  125370.37\n",
      "18   91749.16       114175.79        294919.57  124266.90\n",
      "19   86419.70       153514.11             0.00  122776.86\n",
      "20   76253.86       113867.30        298664.47  118474.03\n",
      "21   78389.47       153773.43        299737.29  111313.02\n",
      "22   73994.56       122782.75        303319.26  110352.25\n",
      "23   67532.53       105751.03        304768.73  108733.99\n",
      "24   77044.01        99281.34        140574.81  108552.04\n",
      "25   64664.71       139553.16        137962.62  107404.34\n",
      "26   75328.87       144135.98        134050.07  105733.54\n",
      "27   72107.60       127864.55        353183.81  105008.31\n",
      "28   66051.52       182645.56        118148.20  103282.38\n",
      "29   65605.48       153032.06        107138.38  101004.64\n",
      "30   61994.48       115641.28         91131.24   99937.59\n",
      "31   61136.38       152701.92         88218.23   97483.56\n",
      "32   63408.86       129219.61         46085.25   97427.84\n",
      "33   55493.95       103057.49        214634.81   96778.92\n",
      "34   46426.07       157693.92        210797.67   96712.80\n",
      "35   46014.02        85047.44        205517.64   96479.51\n",
      "36   28663.76       127056.21        201126.82   90708.19\n",
      "37   44069.95        51283.14        197029.42   89949.14\n",
      "38   20229.59        65947.93        185265.10   81229.06\n",
      "39   38558.51        82982.09        174999.30   81005.76\n",
      "40   28754.33       118546.05        172795.67   78239.91\n",
      "41   27892.92        84710.77        164470.71   77798.83\n",
      "42   23640.93        96189.63        148001.11   71498.49\n",
      "43   15505.73       127382.30         35534.17   69758.98\n",
      "44   22177.74       154806.14         28334.72   65200.33\n",
      "45    1000.23       124153.04          1903.93   64926.08\n",
      "46    1315.46       115816.21        297114.46   49490.75\n",
      "47       0.00       135426.92             0.00   42559.73\n",
      "48     542.05        51743.15             0.00   35673.41\n",
      "49       0.00       116983.80         45173.06   14681.40\n",
      "[[165349.2  136897.8  471784.1  192261.83]\n",
      " [162597.7  151377.59 443898.53 191792.06]\n",
      " [153441.51 101145.55 407934.54 191050.39]\n",
      " [144372.41 118671.85 383199.62 182901.99]\n",
      " [142107.34  91391.77 366168.42 166187.94]\n",
      " [131876.9   99814.71 362861.36 156991.12]\n",
      " [134615.46 147198.87 127716.82 156122.51]\n",
      " [130298.13 145530.06 323876.68 155752.6 ]\n",
      " [120542.52 148718.95 311613.29 152211.77]\n",
      " [123334.88 108679.17 304981.62 149759.96]\n",
      " [101913.08 110594.11 229160.95 146121.95]\n",
      " [100671.96  91790.61 249744.55 144259.4 ]\n",
      " [ 93863.75 127320.38 249839.44 141585.52]\n",
      " [ 91992.39 135495.07 252664.93 134307.35]\n",
      " [119943.24 156547.42 256512.92 132602.65]\n",
      " [114523.61 122616.84 261776.23 129917.04]\n",
      " [ 78013.11 121597.55 264346.06 126992.93]\n",
      " [ 94657.16 145077.58 282574.31 125370.37]\n",
      " [ 91749.16 114175.79 294919.57 124266.9 ]\n",
      " [ 86419.7  153514.11      0.   122776.86]\n",
      " [ 76253.86 113867.3  298664.47 118474.03]\n",
      " [ 78389.47 153773.43 299737.29 111313.02]\n",
      " [ 73994.56 122782.75 303319.26 110352.25]\n",
      " [ 67532.53 105751.03 304768.73 108733.99]\n",
      " [ 77044.01  99281.34 140574.81 108552.04]\n",
      " [ 64664.71 139553.16 137962.62 107404.34]\n",
      " [ 75328.87 144135.98 134050.07 105733.54]\n",
      " [ 72107.6  127864.55 353183.81 105008.31]\n",
      " [ 66051.52 182645.56 118148.2  103282.38]\n",
      " [ 65605.48 153032.06 107138.38 101004.64]\n",
      " [ 61994.48 115641.28  91131.24  99937.59]\n",
      " [ 61136.38 152701.92  88218.23  97483.56]\n",
      " [ 63408.86 129219.61  46085.25  97427.84]\n",
      " [ 55493.95 103057.49 214634.81  96778.92]\n",
      " [ 46426.07 157693.92 210797.67  96712.8 ]\n",
      " [ 46014.02  85047.44 205517.64  96479.51]\n",
      " [ 28663.76 127056.21 201126.82  90708.19]\n",
      " [ 44069.95  51283.14 197029.42  89949.14]\n",
      " [ 20229.59  65947.93 185265.1   81229.06]\n",
      " [ 38558.51  82982.09 174999.3   81005.76]\n",
      " [ 28754.33 118546.05 172795.67  78239.91]\n",
      " [ 27892.92  84710.77 164470.71  77798.83]\n",
      " [ 23640.93  96189.63 148001.11  71498.49]\n",
      " [ 15505.73 127382.3   35534.17  69758.98]\n",
      " [ 22177.74 154806.14  28334.72  65200.33]\n",
      " [  1000.23 124153.04   1903.93  64926.08]\n",
      " [  1315.46 115816.21 297114.46  49490.75]\n",
      " [     0.   135426.92      0.    42559.73]\n",
      " [   542.05  51743.15      0.    35673.41]\n",
      " [     0.   116983.8   45173.06  14681.4 ]]\n",
      "[136897.8  151377.59 101145.55 118671.85  91391.77  99814.71 147198.87\n",
      " 145530.06 148718.95 108679.17 110594.11  91790.61 127320.38 135495.07\n",
      " 156547.42 122616.84 121597.55 145077.58 114175.79 153514.11 113867.3\n",
      " 153773.43 122782.75 105751.03  99281.34 139553.16 144135.98 127864.55\n",
      " 182645.56 153032.06 115641.28 152701.92 129219.61 103057.49 157693.92\n",
      "  85047.44 127056.21  51283.14  65947.93  82982.09 118546.05  84710.77\n",
      "  96189.63 127382.3  154806.14 124153.04 115816.21 135426.92  51743.15\n",
      " 116983.8 ]\n",
      "splitting the values in train and test set  \n",
      "x train [[130298.13 145530.06 323876.68 155752.6 ]\n",
      " [119943.24 156547.42 256512.92 132602.65]\n",
      " [  1000.23 124153.04   1903.93  64926.08]\n",
      " [   542.05  51743.15      0.    35673.41]\n",
      " [ 65605.48 153032.06 107138.38 101004.64]\n",
      " [114523.61 122616.84 261776.23 129917.04]\n",
      " [ 61994.48 115641.28  91131.24  99937.59]\n",
      " [ 63408.86 129219.61  46085.25  97427.84]\n",
      " [ 78013.11 121597.55 264346.06 126992.93]\n",
      " [ 23640.93  96189.63 148001.11  71498.49]\n",
      " [ 76253.86 113867.3  298664.47 118474.03]\n",
      " [ 15505.73 127382.3   35534.17  69758.98]\n",
      " [120542.52 148718.95 311613.29 152211.77]\n",
      " [ 91992.39 135495.07 252664.93 134307.35]\n",
      " [ 64664.71 139553.16 137962.62 107404.34]\n",
      " [131876.9   99814.71 362861.36 156991.12]\n",
      " [ 94657.16 145077.58 282574.31 125370.37]\n",
      " [ 28754.33 118546.05 172795.67  78239.91]\n",
      " [     0.   116983.8   45173.06  14681.4 ]\n",
      " [162597.7  151377.59 443898.53 191792.06]\n",
      " [ 93863.75 127320.38 249839.44 141585.52]\n",
      " [ 44069.95  51283.14 197029.42  89949.14]\n",
      " [ 77044.01  99281.34 140574.81 108552.04]\n",
      " [134615.46 147198.87 127716.82 156122.51]\n",
      " [ 67532.53 105751.03 304768.73 108733.99]\n",
      " [ 28663.76 127056.21 201126.82  90708.19]\n",
      " [ 78389.47 153773.43 299737.29 111313.02]\n",
      " [ 86419.7  153514.11      0.   122776.86]\n",
      " [123334.88 108679.17 304981.62 149759.96]\n",
      " [ 38558.51  82982.09 174999.3   81005.76]\n",
      " [  1315.46 115816.21 297114.46  49490.75]\n",
      " [144372.41 118671.85 383199.62 182901.99]\n",
      " [165349.2  136897.8  471784.1  192261.83]\n",
      " [     0.   135426.92      0.    42559.73]\n",
      " [ 22177.74 154806.14  28334.72  65200.33]] \n",
      "x_test [[ 66051.52 182645.56 118148.2  103282.38]\n",
      " [100671.96  91790.61 249744.55 144259.4 ]\n",
      " [101913.08 110594.11 229160.95 146121.95]\n",
      " [ 27892.92  84710.77 164470.71  77798.83]\n",
      " [153441.51 101145.55 407934.54 191050.39]\n",
      " [ 72107.6  127864.55 353183.81 105008.31]\n",
      " [ 20229.59  65947.93 185265.1   81229.06]\n",
      " [ 61136.38 152701.92  88218.23  97483.56]\n",
      " [ 73994.56 122782.75 303319.26 110352.25]\n",
      " [142107.34  91391.77 366168.42 166187.94]\n",
      " [ 55493.95 103057.49 214634.81  96778.92]\n",
      " [ 46014.02  85047.44 205517.64  96479.51]\n",
      " [ 75328.87 144135.98 134050.07 105733.54]\n",
      " [ 46426.07 157693.92 210797.67  96712.8 ]\n",
      " [ 91749.16 114175.79 294919.57 124266.9 ]] y_train [145530.06 156547.42 124153.04  51743.15 153032.06 122616.84 115641.28\n",
      " 129219.61 121597.55  96189.63 113867.3  127382.3  148718.95 135495.07\n",
      " 139553.16  99814.71 145077.58 118546.05 116983.8  151377.59 127320.38\n",
      "  51283.14  99281.34 147198.87 105751.03 127056.21 153773.43 153514.11\n",
      " 108679.17  82982.09 115816.21 118671.85 136897.8  135426.92 154806.14] \n",
      "y_test [182645.56  91790.61 110594.11  84710.77 101145.55 127864.55  65947.93\n",
      " 152701.92 122782.75  91391.77 103057.49  85047.44 144135.98 157693.92\n",
      " 114175.79]\n",
      "[[-0.1403821   2.28593993 -0.63280437 -0.16141583]\n",
      " [ 0.5692117  -1.24096039  0.37552686  0.79125539]\n",
      " [ 0.59465017 -0.51102691  0.21780907  0.83455765]\n",
      " [-0.92249538 -1.51579286 -0.27786722 -0.75388069]\n",
      " [ 1.65079661 -0.87781077  1.58762665  1.87909509]\n",
      " [-0.01625436  0.15939469  1.16810991 -0.12128983]\n",
      " [-1.07956593 -2.24414796 -0.11853428 -0.67413157]\n",
      " [-0.24112469  1.1235571  -0.86213689 -0.2962321 ]\n",
      " [ 0.02242149 -0.03787582  0.78603258  0.00295097]\n",
      " [ 1.41848712 -1.25644297  1.26760194  1.30107013]\n",
      " [-0.3567741  -0.80359112  0.10650537 -0.31261421]\n",
      " [-0.55107837 -1.50272366  0.03664684 -0.31957517]\n",
      " [ 0.04977002  0.79103569 -0.5109594  -0.10442902]\n",
      " [-0.54263284  1.31734166  0.07710403 -0.31415143]\n",
      " [ 0.38632657 -0.37198959  0.7216716   0.32645147]] \n",
      " second \n",
      " [[ 1.17644103  0.84515251  0.94354978  1.0584598 ]\n",
      " [ 0.96420324  1.27283565  0.42738817  0.52024861]\n",
      " [-1.47369826  0.0153175  -1.52350329 -1.05315815]\n",
      " [-1.48308929 -2.79556363 -1.53809178 -1.73325096]\n",
      " [-0.14952431  1.13637282 -0.71716495 -0.21437081]\n",
      " [ 0.85312042 -0.04431628  0.46771725  0.45781109]\n",
      " [-0.22353674 -0.3151007  -0.83981652 -0.23917856]\n",
      " [-0.19454707  0.21199679 -1.18497259 -0.29752752]\n",
      " [ 0.10478723 -0.08388412  0.48740807  0.38982871]\n",
      " [-1.0096458  -1.07019473 -0.4040623  -0.90035675]\n",
      " [ 0.06872897 -0.38396487  0.75036616  0.19177354]\n",
      " [-1.17638797  0.14067421 -1.26581817 -0.94079847]\n",
      " [ 0.97648631  0.9689421   0.84958395  0.97613935]\n",
      " [ 0.39131191  0.45560401  0.3979037   0.55988103]\n",
      " [-0.16880669  0.6131351  -0.48098026 -0.06558473]\n",
      " [ 1.2088001  -0.92947267  1.24226224  1.08725405]\n",
      " [ 0.44593006  0.82758768  0.62707846  0.35210595]\n",
      " [-0.90483959 -0.20234037 -0.21407884 -0.74362606]\n",
      " [-1.49419935 -0.26298539 -1.19196207 -2.22129239]\n",
      " [ 1.83846539  1.07214791  1.86319367  1.89633811]\n",
      " [ 0.42966802  0.13827054  0.37625394  0.72909058]\n",
      " [-0.59092478 -2.81342077 -0.02839248 -0.47139918]\n",
      " [ 0.08492419 -0.95017758 -0.46096486 -0.03890196]\n",
      " [ 1.26493068  0.90993408 -0.55948669  1.06705981]\n",
      " [-0.11002675 -0.69903054  0.79713886 -0.03467182]\n",
      " [-0.90669595  0.12801572  0.00300304 -0.45375209]\n",
      " [ 0.11250125  1.16515207  0.75858643  0.02528783]\n",
      " [ 0.27709192  1.15508553 -1.53809178  0.29180966]\n",
      " [ 1.03371959 -0.585363    0.79877008  0.91913743]\n",
      " [-0.70388936 -1.58289852 -0.19719396 -0.67932305]\n",
      " [-1.46723718 -0.30831009  0.73848951 -1.41201281]\n",
      " [ 1.46491286 -0.19745694  1.39810017  1.68965364]\n",
      " [ 1.89486118  0.51005662  2.07686138  1.90725975]\n",
      " [-1.49419935  0.4529585  -1.53809178 -1.57315149]\n",
      " [-1.0396359   1.20524087 -1.32098255 -1.04678213]]\n",
      "training accuracy: 0.688\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error:  -0.352\n",
      "Standard Deviation:  0.06446704584514479\n",
      "Mean Squared Error:  -0.5740000000000001\n",
      "Standard Deviation:  0.10818502669038817\n",
      "\n",
      "R squared val:  0.11378681302724176\n",
      "Standard Deviation:  0.1641251337654117\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#using panda version 1.4.2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn import datasets\n",
    "from sklearn import tree, model_selection\n",
    "from sklearn.metrics import r2_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df=pd.read_csv('50_Startups.csv')\n",
    "print(\"Given Data\",df)\n",
    "\n",
    "x=df.iloc[:,0:].values\n",
    "print(x)\n",
    "y=df.iloc[:,1].values\n",
    "print(y)\n",
    "x_train,x_test,y_train,y_test=\\\n",
    "train_test_split(x,y,\n",
    "                test_size=0.3,\n",
    "                random_state=0)\n",
    "print(\"splitting the values in train and test set \",\"\\nx train\",x_train,\"\\nx_test\",x_test,\"y_train\",y_train,\"\\ny_test\",y_test)\n",
    "\n",
    "stdsc = StandardScaler()\n",
    "X_train_std = stdsc.fit_transform(x_train)\n",
    "X_test_std = stdsc.transform(x_test)\n",
    "print(X_test_std,\"\\n second \\n\", X_train_std)\n",
    "\n",
    "lr=LogisticRegression(multi_class='multinomial', solver='lbfgs')\n",
    "x_train,y_train = make_classification(n_samples=1000, n_features=10, n_informative=5, n_redundant=5, n_classes=3, random_state=1)\n",
    "lr.fit(x_train,y_train)\n",
    "print(\"training accuracy:\",lr.score(x_train,y_train))\\\n",
    "\n",
    "\n",
    "\n",
    "plt.figure()\n",
    "ax=plt.subplot(111)\n",
    "colors=['red','blue','green','yellow']\n",
    "weights,para=[],[]\n",
    "for i in np.arange(-4,6):\n",
    "    lr.fit(x_train,y_train)\n",
    "    weights.append(lr.coef_[1])\n",
    "    para.append(100*i)\n",
    "    \n",
    "weights =np.array(weights)\n",
    "for column,color in zip(range(weights.shape[1]),colors):\n",
    "    plt.plot(para,weights[:,column],\n",
    "             label=df.columns[column],\n",
    "             color=color)\n",
    "    \n",
    "\n",
    "seed=42\n",
    "kfold = model_selection.KFold(n_splits=10)\n",
    "model = tree.DecisionTreeRegressor()\n",
    "scoring = \"neg_mean_absolute_error\"\n",
    "results = model_selection.cross_val_score(model, x_train, y_train, cv=kfold, scoring=scoring)\n",
    "print(\"Mean Absolute Error: \", results.mean())\n",
    "print(\"Standard Deviation: \", results.std())\n",
    "scoring = \"neg_mean_squared_error\"\n",
    "results = model_selection.cross_val_score(model, x_train, y_train, cv=kfold, scoring=scoring)\n",
    "print(\"Mean Squared Error: \", results.mean())\n",
    "print(\"Standard Deviation: \", results.std())\n",
    "scoring = \"r2\"\n",
    "results = model_selection.cross_val_score(model, x_train, y_train, cv=kfold, scoring=scoring)\n",
    "print()\n",
    "print(\"R squared val: \", results.mean())\n",
    "print(\"Standard Deviation: \", results.std())\n",
    "\n",
    "\n",
    "plt.axhline(0,color='black',linestyle='--', linewidth=3)\n",
    "plt.xlim([10**(-5),10**5])\n",
    "plt.ylabel(\"weights coeff\")\n",
    "plt.xlabel(\"inverse regulation\")\n",
    "plt.xscale(\"log\")\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35a8322f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
